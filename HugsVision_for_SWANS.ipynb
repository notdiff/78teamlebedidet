{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-tYqcR2Utnx",
        "outputId": "afbb8613-95af-4845-925e-bb4f69affd0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1u6uANPoai_N6ytg9zFbT2ISYVUqWtJ_X\n",
            "To: /content/train_dataset_Минприроды.zip\n",
            "100% 1.76G/1.76G [00:15<00:00, 111MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1u6uANPoai_N6ytg9zFbT2ISYVUqWtJ_X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/train_dataset_Минприроды.zip"
      ],
      "metadata": {
        "id": "cpw_6C4qU68r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/train_dataset_Минприроды/разметка_кликун.zip\n",
        "!unzip /content/train_dataset_Минприроды/разметка_малый.zip\n",
        "!unzip /content/train_dataset_Минприроды/разметка_шипун.zip"
      ],
      "metadata": {
        "id": "DEcR3r7DXhvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/MODELDATA"
      ],
      "metadata": {
        "id": "TUejbR0GYRJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/разметка_малый/images /content/MODELDATA/mal\n",
        "!mv /content/разметка_шипун/images /content/MODELDATA/ship\n",
        "!mv /content/klikun/images /content/MODELDATA/skikun"
      ],
      "metadata": {
        "id": "lsqJ24JJYEfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install hugsvision\n",
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "id": "zU3Rf2XFX1OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrtODVGnf9Fe",
        "outputId": "dd789405-5540-41fd-a842-7d80cb96c77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/MODELDATA/skikun'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdOik_HTdW3e",
        "outputId": "922aac3d-06e6-413c-d5fb-caa844a05838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "756"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip install transformers==4.28.0"
      ],
      "metadata": {
        "id": "y7lfpEJ5gJng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/MODELDATA/ship/masks"
      ],
      "metadata": {
        "id": "7hNCuSR2dipe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def half(path):\n",
        "    folder_path = path\n",
        "\n",
        "    # get a list of all the files in the folder\n",
        "    file_list = os.listdir(folder_path)\n",
        "\n",
        "    # shuffle the list to select random files to delete\n",
        "    random.shuffle(file_list)\n",
        "\n",
        "    # delete every other file in the shuffled list\n",
        "    for i in range(0, len(file_list), 2):\n",
        "        file_path = os.path.join(folder_path, file_list[i])\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "At_Tw0MDc7gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "half('/content/MODELDATA/mal')\n",
        "half('/content/MODELDATA/mal')\n",
        "#half('/content/MODELDATA/mal')\n",
        "\n",
        "half('/content/MODELDATA/ship')\n",
        "half('/content/MODELDATA/ship')\n",
        "#half('/content/MODELDATA/ship')\n",
        "\n",
        "half('/content/MODELDATA/skikun')\n",
        "half('/content/MODELDATA/skikun')\n",
        "#half('/content/MODELDATA/skikun')"
      ],
      "metadata": {
        "id": "Tr0RD2xseuDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hugsvision.dataio.VisionDataset import VisionDataset\n",
        "\n",
        "train, test, id2label, label2id = VisionDataset.fromImageFolder(\n",
        "  \"/content/MODELDATA\",\n",
        "  test_ratio   = 0.15,\n",
        "  balanced     = True,\n",
        "  augmentation = False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts3AN5mfX5hj",
        "outputId": "ba2ea4da-e5e4-4c15-c142-f4d3d86865b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split Datasets...\n",
            "Balance train dataset...\n",
            "The less represented label in train as 750 occurrences\n",
            "Size of train after balancing is 2250\n",
            "Training Dataset Elements:  1912\n",
            "+---------+-----+------+--------+-------+\n",
            "| Dataset | mal | ship | skikun | Total |\n",
            "+---------+-----+------+--------+-------+\n",
            "|  Train  | 621 | 657  |  634   | 1912  |\n",
            "|  Test   | 129 |  93  |  116   |  338  |\n",
            "+---------+-----+------+--------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_model = 'google/vit-base-patch16-224-in21k'"
      ],
      "metadata": {
        "id": "XhJg0lRPZF9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk7M6h_XcIGP",
        "outputId": "e13b2eaf-96cf-4123-a3de-9725df1c83ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1912"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hugsvision.nnet.VisionClassifierTrainer import VisionClassifierTrainer\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "\n",
        "trainer = VisionClassifierTrainer(\n",
        "\tmodel_name   = \"MyKvasirV2Model\",\n",
        "\ttrain        = train,\n",
        "\ttest         = test,\n",
        "\toutput_dir   = \"/content/out/\",\n",
        "\tmax_epochs   = 10,\n",
        "\tbatch_size   = 32,\n",
        "\tlr\t     = 1e-5,\n",
        "\tfp16\t     = True,\n",
        "\n",
        "\tmodel = ViTForImageClassification.from_pretrained(\n",
        "\t    huggingface_model,\n",
        "\t    num_labels = len(label2id),\n",
        "\t    label2id   = label2id,\n",
        "\t    id2label   = id2label\n",
        "\t),\n",
        "\n",
        "\tfeature_extractor = ViTFeatureExtractor.from_pretrained(\n",
        "\t\thuggingface_model,\n",
        "\t),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "E66KVKm8ZIhl",
        "outputId": "53d7b7fb-ee02-4a34-a0c4-c8307e4f80a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 'mal', '1': 'ship', '2': 'skikun'}\n",
            "{'mal': '0', 'ship': '1', 'skikun': '2'}\n",
            "Trainer builded!\n",
            "Start Training!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 17:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.756546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.533713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.421478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.358522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.322278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.303349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.296473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.288467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.342600</td>\n",
              "      <td>0.286772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.342600</td>\n",
              "      <td>0.286050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at: \u001b[93m/content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref, hyp = trainer.evaluate_f1_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl4vjt4F0V8R",
        "outputId": "19e1b5ff-eced-4e10-8515-f314e8b11bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 338/338 [00:20<00:00, 16.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         mal     0.9091    0.8527    0.8800       129\n",
            "        ship     0.9579    0.9785    0.9681        93\n",
            "      skikun     0.8607    0.9052    0.8824       116\n",
            "\n",
            "    accuracy                         0.9053       338\n",
            "   macro avg     0.9092    0.9121    0.9101       338\n",
            "weighted avg     0.9059    0.9053    0.9050       338\n",
            "\n",
            "Logs saved at: \u001b[93m/content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(ref, hyp)\n",
        "labels = list(label2id.keys())\n",
        "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, fmt=\"\")\n",
        "plt.savefig(\"/content/conf_matrix_1.jpg\")"
      ],
      "metadata": {
        "id": "b9RNnlZZ0Wez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/HUGSMODEL.zip /content/out/MYKVASIRV2MODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC4POesuld4O",
        "outputId": "c1412dc7-74a0-4ce9-faee-4a95b4e647a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/out/MYKVASIRV2MODEL/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/trainer/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/trainer/config.json (deflated 48%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/trainer/training_args.bin (deflated 48%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/trainer/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/logs.txt (deflated 56%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/1684643808.8620117/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/1684643808.8620117/events.out.tfevents.1684643808.73e35d9c1ffc.159.3 (deflated 62%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/feature_extractor/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/feature_extractor/preprocessor_config.json (deflated 46%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/model/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/model/config.json (deflated 48%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/model/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/10_2023-05-21-04-36-48/events.out.tfevents.1684643808.73e35d9c1ffc.159.2 (deflated 60%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/30_2023-05-21-04-33-23/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/30_2023-05-21-04-33-23/logs.txt (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/30_2023-05-21-04-33-23/events.out.tfevents.1684643604.73e35d9c1ffc.159.0 (deflated 57%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/30_2023-05-21-04-33-23/1684643604.0667646/ (stored 0%)\n",
            "  adding: content/out/MYKVASIRV2MODEL/30_2023-05-21-04-33-23/1684643604.0667646/events.out.tfevents.1684643604.73e35d9c1ffc.159.1 (deflated 62%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbte28Qsqdyv",
        "outputId": "8f0eba18-a09c-4b88-be5b-ef1282282cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/HUGSMODEL.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "w3PesbU1qsj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/out/MYKVASIRV2MODEL/15_2023-05-20-20-13-18/trainer/pytorch_model.bin"
      ],
      "metadata": {
        "id": "nk_alfqE9408"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hugs_path = \"/content/out/MYKVASIRV2MODEL/15_2023-05-20-20-13-18/trainer\"\n",
        "classifier = VisionClassifierInference(\n",
        "    feature_extractor = ViTFeatureExtractor.from_pretrained(hugs_path),\n",
        "    model = ViTForImageClassification.from_pretrained(hugs_path),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB0E00Oc97fp",
        "outputId": "2597aa21-6a7a-40d6-d61f-f7c21d7f5a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hugs_class = classifier.predict(img_path='/content/lebed_shipun3.jpg')"
      ],
      "metadata": {
        "id": "E_2xiCKx9-Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hugs_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F_VhP2oL-eYK",
        "outputId": "63301e0b-4b5d-4a9d-9931-83703b47fc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ship'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3CoHbJa-fP6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}